{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad07c064-6fc4-43f4-8509-765e7669fc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14371f-a790-49f9-992e-d702c34a1801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ddeddf-9e8d-4644-b08a-7875369e0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/miniconda3/envs/eva/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d286a4a2-f3dd-444d-8f47-d6b635baf61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from rf_calc import receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f6113e-0ec7-43e8-9f68-585f94bf38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed16a04-24e9-405e-96a5-b77f720c2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aafcbd4-a099-4b87-8a95-68a8be925cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jd/Desktop/Computer vision/Extensive_CV/Neural Architecture/Others'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81aadd9e-fcff-4da1-b5c2-5b7417c59da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205b322f-5205-4493-be00-ed447674ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gpu():\n",
    "    \"\"\"Considering we have GPUs\"\"\"\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return None\n",
    "    \n",
    "def gpu_info():\n",
    "    gpu_info = os.system(\"nvidia-smi\")\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "        print('Not connected to a GPU')\n",
    "    else:\n",
    "        print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322649b2-b20a-493a-adef-6322f6f3db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d344ab6-b1ff-44bf-b1de-661cd48b671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe247fe7b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available() #chjecking if cuda is available or not\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") #if gpu is available then device = cuda else cpu\n",
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a18620c7-72b9-4d2e-bf52-9c2f9615a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_type = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=(0.1307),std=(0.3081))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13dca162-c9af-4569-bab2-169c50ffb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist_train = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('/home/jd/Desktop/Computer vision/Extensive_CV/data/',transform=transform_type, train=True, download=True),\n",
    "    batch_size=batch_size, shuffle=True,**kwargs\n",
    ")\n",
    "\n",
    "mnist_test = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('/home/jd/Desktop/Computer vision/Extensive_CV/data/',transform=transform_type, train=False, download=True),\n",
    "    batch_size=batch_size, shuffle=True,**kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e23c2c-4cb9-4af8-9ae5-5f28f28f9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c0647b5-b9a2-4051-85c1-873461013f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=1, padding=0,bias=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU())  #op = 26 * 26\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=1, padding=0,bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU())#op = 24 * 24\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), stride=1, padding=0,bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()) #op = 22 * 22\n",
    "        \n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2,stride=2) #op = 11 * 11\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=1, padding=1,bias=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())  #op = 11 * 11\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=0,bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())  #op = 9 * 9\n",
    "        \n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=0,bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())  #op = 7 * 7\n",
    "        \n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2,stride=2) #op = 4 * 4\n",
    "        \n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=1, padding=1,bias=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU() ) #op = 4 * 4\n",
    "        \n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=1, padding=1,bias=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()) #op = 2 * 2\n",
    "        \n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=10, kernel_size=(3,3), stride=1, padding=0,bias=True) )#op = 1 * 1\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3(self.conv2(self.conv1(x)))\n",
    "        x = self.mp1(x)\n",
    "        \n",
    "        x = self.conv6(self.conv5(self.conv4(x)))\n",
    "        x = self.mp2(x)\n",
    "        \n",
    "        x = self.conv9(self.conv8(self.conv7(x)))\n",
    "        x = x.view(-1,10)\n",
    "        return F.log_softmax(x,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10a23fea-57da-4fc8-b3ec-5eb41e72b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "model = MnistModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84c45869-87f0-4d8d-91a9-5539ea36922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              80\n",
      "       BatchNorm2d-2            [-1, 8, 26, 26]              16\n",
      "              ReLU-3            [-1, 8, 26, 26]               0\n",
      "            Conv2d-4           [-1, 16, 24, 24]           1,168\n",
      "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
      "              ReLU-6           [-1, 16, 24, 24]               0\n",
      "            Conv2d-7           [-1, 16, 22, 22]           2,320\n",
      "       BatchNorm2d-8           [-1, 16, 22, 22]              32\n",
      "              ReLU-9           [-1, 16, 22, 22]               0\n",
      "        MaxPool2d-10           [-1, 16, 11, 11]               0\n",
      "           Conv2d-11           [-1, 32, 11, 11]           4,640\n",
      "      BatchNorm2d-12           [-1, 32, 11, 11]              64\n",
      "             ReLU-13           [-1, 32, 11, 11]               0\n",
      "           Conv2d-14             [-1, 64, 9, 9]          18,496\n",
      "      BatchNorm2d-15             [-1, 64, 9, 9]             128\n",
      "             ReLU-16             [-1, 64, 9, 9]               0\n",
      "           Conv2d-17             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-18             [-1, 64, 7, 7]             128\n",
      "             ReLU-19             [-1, 64, 7, 7]               0\n",
      "        MaxPool2d-20             [-1, 64, 3, 3]               0\n",
      "           Conv2d-21            [-1, 128, 3, 3]          73,856\n",
      "      BatchNorm2d-22            [-1, 128, 3, 3]             256\n",
      "             ReLU-23            [-1, 128, 3, 3]               0\n",
      "           Conv2d-24            [-1, 256, 3, 3]         295,168\n",
      "      BatchNorm2d-25            [-1, 256, 3, 3]             512\n",
      "             ReLU-26            [-1, 256, 3, 3]               0\n",
      "           Conv2d-27             [-1, 10, 1, 1]          23,050\n",
      "================================================================\n",
      "Total params: 456,874\n",
      "Trainable params: 456,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.89\n",
      "Params size (MB): 1.74\n",
      "Estimated Total Size (MB): 2.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model=model,input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5243910-a7f4-400b-80a7-806263af78ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================Reciptive Field Calculator========================================\n",
      "|    | Kernel_size   | Padding   |   Stride | Input_Img_size   | Output_Img_size   | Receptive_field   |\n",
      "|---:|:--------------|:----------|---------:|:-----------------|:------------------|:------------------|\n",
      "|  0 | 3*3           | NO        |        1 | 28*28            | 26*26             | 3*3               |\n",
      "|  1 | 3*3           | NO        |        1 | 26*26            | 24*24             | 5*5               |\n",
      "|  2 | 3*3           | NO        |        1 | 24*24            | 22*22             | 7*7               |\n",
      "|  3 | 2*2           | NO        |        2 | 22*22            | 11*11             | 8*8               |\n",
      "|  4 | 3*3           | 1         |        1 | 11*11            | 11*11             | 12*12             |\n",
      "|  5 | 3*3           | NO        |        1 | 11*11            | 9*9               | 16*16             |\n",
      "|  6 | 3*3           | NO        |        1 | 9*9              | 7*7               | 20*20             |\n",
      "|  7 | 2*2           | NO        |        2 | 7*7              | 3*3               | 22*22             |\n",
      "|  8 | 3*3           | 1         |        1 | 3*3              | 3*3               | 30*30             |\n",
      "|  9 | 3*3           | 1         |        1 | 3*3              | 3*3               | 38*38             |\n",
      "| 10 | 3*3           | NO        |        1 | 3*3              | 1*1               | 46*46             |\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "df = receptive_field(model,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67f26b97-27f5-4233-8137-eca7358e27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,model,optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def update(self,target_pred,target):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(target_pred,target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935ab22-1c0b-49d9-b66c-3c53fd779e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28ffc3cb-be36-42af-8260-5a025bd712f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, optimizer, and criterion\n",
    "model = MnistModel().to(device)\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01,momentum=0,dampening=0,weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47505f42-abfe-40e8-93c6-36932fc5206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "091f64c1-c96c-4d69-bf18-52b9dc025519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainning(model,device,train_data,optimizer,epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(train_data,colour = '\\x1b[34m')\n",
    "    \n",
    "    for index_id,(data,target) in enumerate(pbar):\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        output = model(data)\n",
    "        loss = agent.update(output,target)\n",
    "        total_loss+=loss\n",
    "        correct += output.argmax(dim = 1).eq(target).sum().item()\n",
    "        processed += len(data)\n",
    "        pbar.set_description(f\"Train ==> Epochs: {epochs} Batch:  {index_id} loss: {loss} Accuracy: { correct/processed *100 :.2f}% \")\n",
    "\n",
    "    acc = correct /processed\n",
    "    total_loss = total_loss.item()/processed\n",
    "    return total_loss, acc\n",
    "\n",
    "def testing(model,device,test_data,optimizer,epochs):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    \n",
    "    pbar= tqdm(test_data)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for id_x,(data,target) in enumerate(pbar):\n",
    "            data,target = data.to(device),target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target,reduce='sum').item()\n",
    "            pred  = output.argmax(dim =1,keepdim = True)\n",
    "\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            processed += len(data)\n",
    "            \n",
    "            pbar.set_description(f\"Test ==> Epochs: {epochs} Batch:  {id_x} loss: {test_loss/processed} Accuracy: { correct / processed *100 :.2f}% \")\n",
    "        \n",
    "    acc = correct / processed\n",
    "    test_loss /= processed\n",
    "    return test_loss,acc,pred,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "671ca56d-fbb1-4966-816a-6351e98aefd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 0 Batch:  468 loss: 0.06841827183961868 Accuracy: 95.03% : 100\n",
      "Test ==> Epochs: 0 Batch:  78 loss: 0.0005501965327188372 Accuracy: 98.01% : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,train_losses:0.0015599090576171874, test_losses:0.0005501965327188372,Reward: 0.152\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 1 Batch:  468 loss: 0.1374596506357193 Accuracy: 98.49% : 100%\n",
      "Test ==> Epochs: 1 Batch:  78 loss: 0.0003803044135682285 Accuracy: 98.60% : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,train_losses:0.0004318549474080404, test_losses:0.0003803044135682285,Reward: 0.125\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 2 Batch:  468 loss: 0.03598952665925026 Accuracy: 99.00% : 100\n",
      "Test ==> Epochs: 2 Batch:  78 loss: 0.0002990375589346513 Accuracy: 98.93% : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2,train_losses:0.00029518038431803386, test_losses:0.0002990375589346513,Reward: 0.145\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 3 Batch:  468 loss: 0.010728192515671253 Accuracy: 99.26% : 10\n",
      "Test ==> Epochs: 3 Batch:  78 loss: 0.0002677863194141537 Accuracy: 98.73% : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3,train_losses:0.0002202868938446045, test_losses:0.0002677863194141537,Reward: 0.164\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 4 Batch:  468 loss: 0.009714871644973755 Accuracy: 99.44% : 10\n",
      "Test ==> Epochs: 4 Batch:  78 loss: 0.00022366510787978768 Accuracy: 99.08% : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4,train_losses:0.0001709702173868815, test_losses:0.00022366510787978768,Reward: 0.156\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 5 Batch:  468 loss: 0.027885062620043755 Accuracy: 99.59% : 10\n",
      "Test ==> Epochs: 5 Batch:  78 loss: 0.00023038010069867596 Accuracy: 99.01% : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5,train_losses:0.00013613319396972657, test_losses:0.00023038010069867596,Reward: 0.133\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 6 Batch:  468 loss: 0.011307927779853344 Accuracy: 99.69% : 10\n",
      "Test ==> Epochs: 6 Batch:  78 loss: 0.00020558639244991356 Accuracy: 99.16% : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6,train_losses:0.00011239794890085857, test_losses:0.00020558639244991356,Reward: 0.164\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 7 Batch:  468 loss: 0.006181469652801752 Accuracy: 99.78% : 10\n",
      "Test ==> Epochs: 7 Batch:  78 loss: 0.00019299411419779062 Accuracy: 99.20% : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7,train_losses:8.968451817830403e-05, test_losses:0.00019299411419779062,Reward: 0.141\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 8 Batch:  468 loss: 0.016139620915055275 Accuracy: 99.83% : 10\n",
      "Test ==> Epochs: 8 Batch:  78 loss: 0.00020224455051939003 Accuracy: 99.10% : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8,train_losses:7.270353635152182e-05, test_losses:0.00020224455051939003,Reward: 0.188\n",
      "================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 9 Batch:  468 loss: 0.008511875756084919 Accuracy: 99.88% : 10\n",
      "Test ==> Epochs: 9 Batch:  78 loss: 0.00019493792654247955 Accuracy: 99.24% : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9,train_losses:6.083915630976359e-05, test_losses:0.00019493792654247955,Reward: 0.141\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "train_accuracy = []\n",
    "test_losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "for EPOCHS in range(10):\n",
    "    train_loss, train_acc = trainning(model,device,mnist_train,optimizer,EPOCHS)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy.append(train_acc)\n",
    "\n",
    "    test_loss,test_acc,test_pred,test_target = testing(model,device,mnist_test,optimizer,EPOCHS)\n",
    "\n",
    "    test_accuracy.append(test_acc)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Calculate the reward\n",
    "    reward = test_pred.eq(test_target).float().mean()\n",
    "    # Update the model\n",
    "    clean_gpu()\n",
    "    print(f'Epoch: {EPOCHS},train_losses:{train_losses[-1]}, test_losses:{test_losses[-1]},Reward: {reward:.3f}')\n",
    "    print ( \"================================================================================\" *2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afef9ac-9bc5-49ba-a25b-8459a82e72a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
