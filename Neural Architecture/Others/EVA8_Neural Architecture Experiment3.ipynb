{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Important Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "#Enabling interactive secession for the notebook and save in very 20 second.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0m2JWFliFfKT"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch                                #Importing Torch module as ml framework desined for reserchers and developer.\n",
    "import torch.nn as nn                       #NN module have classes and modules to implement and train the neural network.\n",
    "import torch.nn.functional as F             #Functional provides module like activations,losses etc\n",
    "import torch.optim as optim                 #Importing optimizer moduke from torch\n",
    "from torchvision import datasets, transforms#Importing Torch vision for datasets and data transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from ../kernel_viz import print_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a module created by me to calculate receptive field.Having copule of bugs but works fine.\n",
    "from  rf_calc import receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "gkEw1JvHNc2x",
    "outputId": "60ce05b8-42fb-4717-c380-35015b749e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__ #checking Troch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda GPU avalable: True\n"
     ]
    }
   ],
   "source": [
    "#Checking for torch GPU support\n",
    "print(f\"Is cuda GPU avalable: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffb26bc7c10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available() #chjecking if cuda is available or not\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") #if gpu is available then device = cuda else cpu\n",
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining train loader and test loader \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=True, download=True,  #downloading the data at /data folder,its for trainning\n",
    "                    transform=transforms.Compose([       #data transformation includes converting to tensor and normalizing with the mean and std of the dataset\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "### Trainning Function\n",
    "\n",
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()   #model set to trainning\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar): # Iterating through data and target\n",
    "        data, target = data.to(device), target.to(device)  #pushing data and target to gpu\n",
    "        optimizer.zero_grad() # making all the gradients to zero\n",
    "        output= model(data) # predicting op\n",
    "        type(output)\n",
    "        loss = F.nll_loss(output, target) # calculating loss\n",
    "        loss.backward()  # This is backpropagation in action.\n",
    "        optimizer.step() # Updating old weights with new \n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "### Testing Function\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()  #Model set to evaluation mode.\n",
    "    test_loss = 0  \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output= model(data)   #predicting the test data\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Class defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "h_Cx9q2QFgM7"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=1, padding=0,bias=True)  #op = 26 * 26\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=1, padding=0,bias=True)  #op = 24 * 24\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), stride=1, padding=0,bias=True)  #op = 22 * 22\n",
    "        \n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2,stride=2) #op = 11 * 11\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=1, padding=1,bias=True)  #op = 11 * 11\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=0,bias=True)  #op = 9 * 9\n",
    "        self.conv6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=0,bias=True)  #op = 7 * 7\n",
    "        \n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2,stride=2) #op = 4 * 4\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=1, padding=1,bias=True)  #op = 4 * 4\n",
    "        self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=1, padding=1,bias=True)  #op = 2 * 2\n",
    "        self.conv9 = nn.Conv2d(in_channels=256, out_channels=10, kernel_size=(3,3), stride=1, padding=0,bias=True)  #op = 1 * 1\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv3(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
    "        x = self.mp1(x)\n",
    "        \n",
    "        x = F.relu(self.conv6(F.relu(self.conv5(F.relu(self.conv4(x))))))\n",
    "        x = self.mp2(x)\n",
    "        \n",
    "        x = self.conv9(F.relu(self.conv8(F.relu(self.conv7(x)))))\n",
    "        x = x.view(-1,10)\n",
    "        return F.log_softmax(x,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):       #created a model class as Net  inhereate properties from nn.Modules\n",
    "    def __init__(self):     #defining Init function.\n",
    "        super(Net1, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = (2,2),stride=2)\n",
    "        self.conv = nn.Conv2d( in_channels=1,out_channels=1,kernel_size=(3,3),stride=1,padding= 1, bias=False, padding_mode = 'replicate')\n",
    "    \n",
    "    def forward(self, x):  #forward functions\n",
    "        x = self.conv(self.maxpool(x))\n",
    "        return x                          #Final log softmax layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xdydjYTZFyi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              80\n",
      "            Conv2d-2           [-1, 16, 24, 24]           1,168\n",
      "            Conv2d-3           [-1, 16, 22, 22]           2,320\n",
      "         MaxPool2d-4           [-1, 16, 11, 11]               0\n",
      "            Conv2d-5           [-1, 32, 11, 11]           4,640\n",
      "            Conv2d-6             [-1, 64, 9, 9]          18,496\n",
      "            Conv2d-7             [-1, 64, 7, 7]          36,928\n",
      "         MaxPool2d-8             [-1, 64, 3, 3]               0\n",
      "            Conv2d-9            [-1, 128, 3, 3]          73,856\n",
      "           Conv2d-10            [-1, 256, 3, 3]         295,168\n",
      "           Conv2d-11             [-1, 10, 1, 1]          23,050\n",
      "================================================================\n",
      "Total params: 455,706\n",
      "Trainable params: 455,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 1.74\n",
      "Estimated Total Size (MB): 2.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary   #importing torchsummary.\n",
    "model = Net().to(device) #creating model and sending it to \"CPU/CUDA\"\n",
    "summary(model, input_size=(1, 28, 28))  #Printing the model summary details "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the Receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================Reciptive Field Calculator========================================\n",
      "|    | Kernel_size   | Padding   |   Stride | Input_Img_size   | Output_Img_size   | Receptive_field   |\n",
      "|---:|:--------------|:----------|---------:|:-----------------|:------------------|:------------------|\n",
      "|  0 | 3*3           | NO        |        1 | 28*28            | 26*26             | 3*3               |\n",
      "|  1 | 3*3           | NO        |        1 | 26*26            | 24*24             | 5*5               |\n",
      "|  2 | 3*3           | NO        |        1 | 24*24            | 22*22             | 7*7               |\n",
      "|  3 | 2*2           | NO        |        2 | 22*22            | 11*11             | 8*8               |\n",
      "|  4 | 3*3           | 1         |        1 | 11*11            | 11*11             | 12*12             |\n",
      "|  5 | 3*3           | NO        |        1 | 11*11            | 9*9               | 16*16             |\n",
      "|  6 | 3*3           | NO        |        1 | 9*9              | 7*7               | 20*20             |\n",
      "|  7 | 2*2           | NO        |        2 | 7*7              | 3*3               | 22*22             |\n",
      "|  8 | 3*3           | 1         |        1 | 3*3              | 3*3               | 30*30             |\n",
      "|  9 | 3*3           | 1         |        1 | 3*3              | 3*3               | 38*38             |\n",
      "| 10 | 3*3           | NO        |        1 | 3*3              | 1*1               | 46*46             |\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_df = receptive_field(model_obj=model,input_image=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fDefDhaFlwH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MMWbLWO6FuHb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Reduced the parameter 1 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              80\n",
      "            Conv2d-2           [-1, 16, 24, 24]           1,168\n",
      "            Conv2d-3           [-1, 16, 22, 22]           2,320\n",
      "         MaxPool2d-4           [-1, 16, 11, 11]               0\n",
      "            Conv2d-5           [-1, 32, 11, 11]           4,640\n",
      "            Conv2d-6             [-1, 64, 9, 9]          18,496\n",
      "            Conv2d-7             [-1, 64, 7, 7]          36,928\n",
      "         MaxPool2d-8             [-1, 64, 3, 3]               0\n",
      "            Conv2d-9            [-1, 128, 3, 3]          73,856\n",
      "           Conv2d-10            [-1, 256, 3, 3]         295,168\n",
      "           Conv2d-11             [-1, 10, 1, 1]          23,050\n",
      "================================================================\n",
      "Total params: 455,706\n",
      "Trainable params: 455,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 1.74\n",
      "Estimated Total Size (MB): 2.05\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.19180721044540405 batch_id=468: 100%|██| 469/469 [00:09<00:00, 51.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1545, Accuracy: 9510/10000 (95.1000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print (f\"Model Reduced the parameter {i} times the base model\")\n",
    "model = Net().to(device) #creating model and sending it to \"CPU/CUDA\"\n",
    "summary(model, input_size=(1, 28, 28))  #Printing the model summary details \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # setting the optimizer\n",
    "\n",
    "for epoch in range(1, 2):    # running is for 1 epoch\n",
    "    train(model, device, train_loader, optimizer, epoch)  # Running the Train Function\n",
    "    test(model, device, test_loader)    # running the test Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Take one image and send it to conv and see what's happening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader): # Iterating through data and target\n",
    "    data, target = data.to(device), target.to(device)  #pushing data and target to gpu\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(data[0].reshape(28,28,-1).to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_val,x1,x2,x3,x4,x5 = model(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_val"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It was ReLU causing issues before the output layer. The model's ReLU was initially filtering out negative output values as it passed the output of the convolution layer through. As a result, the LOG SOFTMAX function could only handle positive numbers, which adversely affected the model's performance.\n",
    "Due to the fact that we used two different activation functions, ReLU and LOG SOFTMAX, and that the output values were instead the outcomes of an activation function, backpropagation was unable to help the neural network fine-tune its weights.\n",
    "The LOG SOFTMAX operation took over and provided the network with exact input when the ReLU activation function was disabled. And the model Started performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape\n",
    "x2.shape\n",
    "x3.shape\n",
    "x4.shape\n",
    "x5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between with relu and without relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.relu(x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.log_softmax(F.relu(x5),-1)  #Because Relu set the last layer's negative information to zero, the majority of values are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.log_softmax(F.relu(x5),-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "l = F.nll_loss(F.log_softmax(F.relu(x5),-1).squeeze() , target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.log_softmax(x5,-1)  #Because Relu set the last layer's negative information to zero, the majority of values are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.log_softmax(x5,-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "F.nll_loss(F.log_softmax(x5,-1).squeeze() , target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Visualize some kernels we trainned"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "import numpy as np\n",
    "\n",
    "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "def print_layer(filter):\n",
    "    # layer = ['conv1','conv2','conv3','conv4','conv5','conv6','conv7']\n",
    "    filter = filter\n",
    "    visTensor(filter, ch=0, allkernels=False)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv7.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv6.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv5.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv4.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv3.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv2.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer(model.conv1.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
