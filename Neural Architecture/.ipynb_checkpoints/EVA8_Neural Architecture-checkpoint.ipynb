{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Important Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "#Enabling interactive secession for the notebook and save in very 20 second.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0m2JWFliFfKT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/miniconda3/envs/eva/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch                                #Importing Torch module as ml framework desined for reserchers and developer.\n",
    "import torch.nn as nn                       #NN module have classes and modules to implement and train the neural network.\n",
    "import torch.nn.functional as F             #Functional provides module like activations,losses etc\n",
    "import torch.optim as optim                 #Importing optimizer moduke from torch\n",
    "from torchvision import datasets, transforms#Importing Torch vision for datasets and data transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a module created by me to calculate receptive field.Having copule of bugs but works fine.\n",
    "from  rf_calc import receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "gkEw1JvHNc2x",
    "outputId": "60ce05b8-42fb-4717-c380-35015b749e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__ #checking Troch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda GPU avalable: True\n"
     ]
    }
   ],
   "source": [
    "#Checking for torch GPU support\n",
    "print(f\"Is cuda GPU avalable: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Class defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "h_Cx9q2QFgM7"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):       #created a model class as Net  inhereate properties from nn.Modules\n",
    "    def __init__(self):     #defining Init function.\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)    #input:28*28  OUtput:28*28 RF:3*3   (RF Considering MaxPooling doubles the RF for now)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)   #input:28*28  OUtput:28*28 RF:5*5\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                #input:28*28  OUtput:14*14 RF:10*10\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  #input:14*14  OUtput:14*14 RF:12*12\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) #input:14*14  OUtput:14*14 RF:14*14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                #input:14*14  OUtput:7*7 RF:28*28\n",
    "        self.conv5 = nn.Conv2d(256, 512, 3)            #input:7*7    OUtput:5*5 RF:30*30\n",
    "        self.conv6 = nn.Conv2d(512, 1024, 3)           #input:5*5    OUtput:3*3 RF:32*32\n",
    "        self.conv7 = nn.Conv2d(1024, 10, 3)            #input:3*3    OUtput:1*1 RF:34*34\n",
    "        \n",
    "    def forward(self, x):  #forward functions\n",
    "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) #maxpool--> relu-->conv2-->relu-->conv1\n",
    "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))) #maxpool--> relu-->conv4-->relu-->conv3\n",
    "        x = F.relu(self.conv6(F.relu(self.conv5(x))))             #relu-->conv6-->relu-->conv5\n",
    "        x = F.relu(self.conv7(x))                                 #relu-->conv7\n",
    "        x = x.view(-1, 10)                                        #Changing dimention of data.\n",
    "        return F.log_softmax(x,-1)                                   #Final log softmax layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Flow is Conv1-->relu-->Conv2-->relu-->Maxpool1-->Conv3-->relu-->Conv4-->relu-->Maxpool2-->Conv5  -->relu-->Conv6-->relu-->-->Conv7-->relu-->softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xdydjYTZFyi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
      "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
      "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
      "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
      "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
      "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
      "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
      "================================================================\n",
      "Total params: 6,379,786\n",
      "Trainable params: 6,379,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.51\n",
      "Params size (MB): 24.34\n",
      "Estimated Total Size (MB): 25.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary   #importing torchsummary.\n",
    "use_cuda = torch.cuda.is_available() #chjecking if cuda is available or not\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") #if gpu is available then device = cuda else cpu\n",
    "model = Net().to(device) #creating model and sending it to \"CPU/CUDA\"\n",
    "summary(model, input_size=(1, 28, 28))  #Printing the model summary details "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the Receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================Reciptive Field Calculator========================================\n",
      "|    | Kernel_size   | Padding   |   Stride | Input_Img_size   | Output_Img_size   | Receptive_field   |\n",
      "|---:|:--------------|:----------|---------:|:-----------------|:------------------|:------------------|\n",
      "|  0 | 3*3           | 1         |        1 | 28*28            | 28*28             | 3*3               |\n",
      "|  1 | 3*3           | 1         |        1 | 28*28            | 28*28             | 5*5               |\n",
      "|  2 | 2*2           | NO        |        2 | 28*28            | 14*14             | 6*6               |\n",
      "|  3 | 3*3           | 1         |        1 | 14*14            | 14*14             | 10*10             |\n",
      "|  4 | 3*3           | 1         |        1 | 14*14            | 14*14             | 14*14             |\n",
      "|  5 | 2*2           | NO        |        2 | 14*14            | 7*7               | 16*16             |\n",
      "|  6 | 3*3           | NO        |        1 | 7*7              | 5*5               | 24*24             |\n",
      "|  7 | 3*3           | NO        |        1 | 5*5              | 3*3               | 32*32             |\n",
      "|  8 | 3*3           | NO        |        1 | 3*3              | 1*1               | 40*40             |\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_df = receptive_field(model_obj=model,input_image=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DqTWLaM5GHgH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f79f90d3af0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DqTWLaM5GHgH"
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining train loader and test loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DqTWLaM5GHgH"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,  #downloading the data at /data folder,its for trainning\n",
    "                    transform=transforms.Compose([       #data transformation includes converting to tensor and normalizing with the mean and std of the dataset\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8fDefDhaFlwH"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()   #model set to trainning\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar): # Iterating through data and target\n",
    "        data, target = data.to(device), target.to(device)  #pushing data and target to gpu\n",
    "        optimizer.zero_grad() # making all the gradients to zero\n",
    "        output = model(data) # predicting op\n",
    "        loss = F.nll_loss(output, target) # calculating loss\n",
    "        loss.backward()  # This is backpropagation in action.\n",
    "        optimizer.step() # Updating old weights with new \n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8fDefDhaFlwH"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()  #Model set to evaluation mode.\n",
    "    test_loss = 0  \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)   #predicting the test data\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MMWbLWO6FuHb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=1.9944766759872437 batch_id=468: 100%|███| 469/469 [00:08<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9712, Accuracy: 2805/10000 (28%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net().to(device)  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # setting the optimizer\n",
    "\n",
    "for epoch in range(1, 2):    # running is for 1 epoch\n",
    "    train(model, device, train_loader, optimizer, epoch)  # Running the Train Function\n",
    "    test(model, device, test_loader)    # running the test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "So5uk4EkHW6R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
