{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Important Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "#Enabling interactive secession for the notebook and save in very 20 second.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0m2JWFliFfKT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/anaconda3/envs/tsai/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch                                #Importing Torch module as ml framework desined for reserchers and developer.\n",
    "import torch.nn as nn                       #NN module have classes and modules to implement and train the neural network.\n",
    "import torch.nn.functional as F             #Functional provides module like activations,losses etc\n",
    "import torch.optim as optim                 #Importing optimizer moduke from torch\n",
    "from torchvision import datasets, transforms#Importing Torch vision for datasets and data transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a module created by me to calculate receptive field.Having copule of bugs but works fine.\n",
    "from  rf_calc import receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "gkEw1JvHNc2x",
    "outputId": "60ce05b8-42fb-4717-c380-35015b749e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__ #checking Troch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda GPU avalable: True\n"
     ]
    }
   ],
   "source": [
    "#Checking for torch GPU support\n",
    "print(f\"Is cuda GPU avalable: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8b81e8b30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available() #chjecking if cuda is available or not\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") #if gpu is available then device = cuda else cpu\n",
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining train loader and test loader \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,  #downloading the data at /data folder,its for trainning\n",
    "                    transform=transforms.Compose([       #data transformation includes converting to tensor and normalizing with the mean and std of the dataset\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "### Trainning Function\n",
    "\n",
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()   #model set to trainning\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar): # Iterating through data and target\n",
    "        data, target = data.to(device), target.to(device)  #pushing data and target to gpu\n",
    "        optimizer.zero_grad() # making all the gradients to zero\n",
    "        output = model(data) # predicting op\n",
    "        loss = F.nll_loss(output, target) # calculating loss\n",
    "        loss.backward()  # This is backpropagation in action.\n",
    "        optimizer.step() # Updating old weights with new \n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "### Testing Function\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()  #Model set to evaluation mode.\n",
    "    test_loss = 0  \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)   #predicting the test data\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Class defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h_Cx9q2QFgM7"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):       #created a model class as Net  inhereate properties from nn.Modules\n",
    "    def __init__(self,x_times = 1):     #defining Init function.\n",
    "        super(Net, self).__init__()\n",
    "        x_times = x_times\n",
    "        self.conv1 = nn.Conv2d(1, 32//x_times, 3, padding=1)    #input:28*28  OUtput:28*28 RF:3*3   (RF Considering MaxPooling doubles the RF for now)\n",
    "        self.conv2 = nn.Conv2d(32//x_times, 64//x_times, 3, padding=1)   #input:28*28  OUtput:28*28 RF:5*5\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                #input:28*28  OUtput:14*14 RF:10*10\n",
    "        self.conv3 = nn.Conv2d(64//x_times, 128//x_times, 3, padding=1)  #input:14*14  OUtput:14*14 RF:12*12\n",
    "        self.conv4 = nn.Conv2d(128//x_times, 256//x_times, 3, padding=1) #input:14*14  OUtput:14*14 RF:14*14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                #input:14*14  OUtput:7*7 RF:28*28\n",
    "        self.conv5 = nn.Conv2d(256//x_times, 512//x_times, 3)            #input:7*7    OUtput:5*5 RF:30*30\n",
    "        self.conv6 = nn.Conv2d(512//x_times, 1024//x_times, 3)           #input:5*5    OUtput:3*3 RF:32*32\n",
    "        self.conv7 = nn.Conv2d(1024//x_times, 10, 3)            #input:3*3    OUtput:1*1 RF:34*34\n",
    "        \n",
    "    def forward(self, x):  #forward functions\n",
    "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) #maxpool--> relu-->conv2-->relu-->conv1\n",
    "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))) #maxpool--> relu-->conv4-->relu-->conv3\n",
    "        x = F.relu(self.conv6(F.relu(self.conv5(x))))             #relu-->conv6-->relu-->conv5\n",
    "        x = self.conv7(x)                                         #conv7\n",
    "        x = x.view(-1, 10)                                        #Changing dimention of data.\n",
    "        return F.log_softmax(x,-1)                                   #Final log softmax layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xdydjYTZFyi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
      "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
      "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
      "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
      "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
      "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
      "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
      "================================================================\n",
      "Total params: 6,379,786\n",
      "Trainable params: 6,379,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.51\n",
      "Params size (MB): 24.34\n",
      "Estimated Total Size (MB): 25.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary   #importing torchsummary.\n",
    "model = Net(x_times = 1).to(device) #creating model and sending it to \"CPU/CUDA\"\n",
    "summary(model, input_size=(1, 28, 28))  #Printing the model summary details "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the Receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================Reciptive Field Calculator========================================\n",
      "|    | Kernel_size   | Padding   |   Stride | Input_Img_size   | Output_Img_size   | Receptive_field   |\n",
      "|---:|:--------------|:----------|---------:|:-----------------|:------------------|:------------------|\n",
      "|  0 | 3*3           | 1         |        1 | 28*28            | 28*28             | 3*3               |\n",
      "|  1 | 3*3           | 1         |        1 | 28*28            | 28*28             | 5*5               |\n",
      "|  2 | 2*2           | NO        |        2 | 28*28            | 14*14             | 6*6               |\n",
      "|  3 | 3*3           | 1         |        1 | 14*14            | 14*14             | 10*10             |\n",
      "|  4 | 3*3           | 1         |        1 | 14*14            | 14*14             | 14*14             |\n",
      "|  5 | 2*2           | NO        |        2 | 14*14            | 7*7               | 16*16             |\n",
      "|  6 | 3*3           | NO        |        1 | 7*7              | 5*5               | 24*24             |\n",
      "|  7 | 3*3           | NO        |        1 | 5*5              | 3*3               | 32*32             |\n",
      "|  8 | 3*3           | NO        |        1 | 3*3              | 1*1               | 40*40             |\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_df = receptive_field(model_obj=model,input_image=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fDefDhaFlwH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MMWbLWO6FuHb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Reduced the parameter 1 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
      "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
      "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
      "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
      "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
      "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
      "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
      "================================================================\n",
      "Total params: 6,379,786\n",
      "Trainable params: 6,379,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.51\n",
      "Params size (MB): 24.34\n",
      "Estimated Total Size (MB): 25.85\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.10171332210302353 batch_id=468: 100%|███████████████████████████| 469/469 [00:08<00:00, 58.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0603, Accuracy: 9812/10000 (98.1200%)\n",
      "\n",
      "Model Reduced the parameter 2 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "            Conv2d-2           [-1, 32, 28, 28]           4,640\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
      "            Conv2d-5          [-1, 128, 14, 14]          73,856\n",
      "         MaxPool2d-6            [-1, 128, 7, 7]               0\n",
      "            Conv2d-7            [-1, 256, 5, 5]         295,168\n",
      "            Conv2d-8            [-1, 512, 3, 3]       1,180,160\n",
      "            Conv2d-9             [-1, 10, 1, 1]          46,090\n",
      "================================================================\n",
      "Total params: 1,618,570\n",
      "Trainable params: 1,618,570\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 6.17\n",
      "Estimated Total Size (MB): 6.93\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05827442929148674 batch_id=468: 100%|███████████████████████████| 469/469 [00:05<00:00, 80.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0639, Accuracy: 9785/10000 (97.8500%)\n",
      "\n",
      "Model Reduced the parameter 3 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 28, 28]             100\n",
      "            Conv2d-2           [-1, 21, 28, 28]           1,911\n",
      "         MaxPool2d-3           [-1, 21, 14, 14]               0\n",
      "            Conv2d-4           [-1, 42, 14, 14]           7,980\n",
      "            Conv2d-5           [-1, 85, 14, 14]          32,215\n",
      "         MaxPool2d-6             [-1, 85, 7, 7]               0\n",
      "            Conv2d-7            [-1, 170, 5, 5]         130,220\n",
      "            Conv2d-8            [-1, 341, 3, 3]         522,071\n",
      "            Conv2d-9             [-1, 10, 1, 1]          30,700\n",
      "================================================================\n",
      "Total params: 725,197\n",
      "Trainable params: 725,197\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.49\n",
      "Params size (MB): 2.77\n",
      "Estimated Total Size (MB): 3.26\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02670036070048809 batch_id=468: 100%|███████████████████████████| 469/469 [00:05<00:00, 80.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 9785/10000 (97.8500%)\n",
      "\n",
      "Model Reduced the parameter 4 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "            Conv2d-2           [-1, 16, 28, 28]           1,168\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4           [-1, 32, 14, 14]           4,640\n",
      "            Conv2d-5           [-1, 64, 14, 14]          18,496\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Conv2d-7            [-1, 128, 5, 5]          73,856\n",
      "            Conv2d-8            [-1, 256, 3, 3]         295,168\n",
      "            Conv2d-9             [-1, 10, 1, 1]          23,050\n",
      "================================================================\n",
      "Total params: 416,458\n",
      "Trainable params: 416,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 1.59\n",
      "Estimated Total Size (MB): 1.97\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.09123865514993668 batch_id=468: 100%|███████████████████████████| 469/469 [00:05<00:00, 80.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0617, Accuracy: 9802/10000 (98.0200%)\n",
      "\n",
      "Model Reduced the parameter 5 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]              60\n",
      "            Conv2d-2           [-1, 12, 28, 28]             660\n",
      "         MaxPool2d-3           [-1, 12, 14, 14]               0\n",
      "            Conv2d-4           [-1, 25, 14, 14]           2,725\n",
      "            Conv2d-5           [-1, 51, 14, 14]          11,526\n",
      "         MaxPool2d-6             [-1, 51, 7, 7]               0\n",
      "            Conv2d-7            [-1, 102, 5, 5]          46,920\n",
      "            Conv2d-8            [-1, 204, 3, 3]         187,476\n",
      "            Conv2d-9             [-1, 10, 1, 1]          18,370\n",
      "================================================================\n",
      "Total params: 267,737\n",
      "Trainable params: 267,737\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.29\n",
      "Params size (MB): 1.02\n",
      "Estimated Total Size (MB): 1.32\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.09373003989458084 batch_id=468: 100%|███████████████████████████| 469/469 [00:05<00:00, 79.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0797, Accuracy: 9734/10000 (97.3400%)\n",
      "\n",
      "Model Reduced the parameter 6 times the base model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 5, 28, 28]              50\n",
      "            Conv2d-2           [-1, 10, 28, 28]             460\n",
      "         MaxPool2d-3           [-1, 10, 14, 14]               0\n",
      "            Conv2d-4           [-1, 21, 14, 14]           1,911\n",
      "            Conv2d-5           [-1, 42, 14, 14]           7,980\n",
      "         MaxPool2d-6             [-1, 42, 7, 7]               0\n",
      "            Conv2d-7             [-1, 85, 5, 5]          32,215\n",
      "            Conv2d-8            [-1, 170, 3, 3]         130,220\n",
      "            Conv2d-9             [-1, 10, 1, 1]          15,310\n",
      "================================================================\n",
      "Total params: 188,146\n",
      "Trainable params: 188,146\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.24\n",
      "Params size (MB): 0.72\n",
      "Estimated Total Size (MB): 0.96\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.13210918009281158 batch_id=468: 100%|███████████████████████████| 469/469 [00:05<00:00, 79.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1070, Accuracy: 9671/10000 (96.7100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,7):\n",
    "    print (f\"Model Reduced the parameter {i} times the base model\")\n",
    "    model = Net(x_times = i).to(device) #creating model and sending it to \"CPU/CUDA\"\n",
    "    summary(model, input_size=(1, 28, 28))  #Printing the model summary details \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # setting the optimizer\n",
    "\n",
    "    for epoch in range(1, 2):    # running is for 1 epoch\n",
    "        train(model, device, train_loader, optimizer, epoch)  # Running the Train Function\n",
    "        test(model, device, test_loader)    # running the test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "So5uk4EkHW6R"
   },
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It was ReLU causing issues before the output layer. The model's ReLU was initially filtering out negative output values as it passed the output of the convolution layer through. As a result, the LOG SOFTMAX function could only handle positive numbers, which adversely affected the model's performance.\n",
    "Due to the fact that we used two different activation functions, ReLU and LOG SOFTMAX, and that the output values were instead the outcomes of an activation function, backpropagation was unable to help the neural network fine-tune its weights.\n",
    "The LOG SOFTMAX operation took over and provided the network with exact input when the ReLU activation function was disabled. And the model Started performing well."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
